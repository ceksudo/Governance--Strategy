# Governance--Strategy
Agent foundations,  AI governance &amp; policy, Cooperative AI,  Law, Value alignment

# Overview
This stream investigates the technical and sociotechnical foundations for a world of cooperative, pluralistic AI agents. We will tackle fundamental challenges in ensuring agent advocates are confidential, trustworthy, and aligned with their usersâ€™ interests. We seek applicants who can bridge concepts from game theory, economics, and AI to build and analyze these systems.

# Research Project Descriptions
* Projects will focus on enabling a future of pluralistic AI advocate agents. We are open to a range of directions, including:

* Theoretical: Formalizing properties of multi-agent systems, such as user-alignment guarantees or conditions for stable cooperation.

* Technical: Developing methods for agent coordination/negotiation, confidentiality and trust, as well as evaluation frameworks.

* Applied: Building a proof-of-concept system, such as an automated arbitration platform for simple disputes, to demonstrate and test these principles.


# Course Revision
* [Dynamic optimization](https://www.youtube.com/playlist?list=PLzm9WhyHDMwFxB_Hnga_slMcfCCgvndvW)
* [PS 231 Strategic Models - Fall 2021](https://www.youtube.com/playlist?list=PLc7nd1hqyQFf5HeiiOtw55D_BnU0nRcD8) || [Website](https://www.robertjcarroll.com/the-weird-world-of-ps-231/) || [Game Theory - Fall 2020](https://www.youtube.com/playlist?list=PLWKV6_7b8ZwnqWYrggjVL4m_cAt0ZIzlQ)
* [Game Theory - Economics Perspoective](https://www.youtube.com/@selcukozyurt/playlists)
